% Exported from Litmaps (https://www.litmaps.com)

@article{largescale_he_2021,
	title = {Large-Scale Deep Learning Optimizations: A Comprehensive Survey.},
	author = {He, Xiaoxin and Xue, Fuzhao and Ren, Xiaozhe and You, Yang},
	journal = {arXiv: Learning},
	year = {2021},
	litmapsId = {110469497}
}


@article{natural_horvth_2021,
	title = {Natural Compression for Distributed Deep Learning},
	author = {Horváth, Samuel and Ho, Chen-Yu and Horváth, Ludovit and Sahu, Atal Narayan and Canini, Marco and Richtárik, Peter},
	journal = {arXiv: Learning},
	year = {2021},
	litmapsId = {261332653}
}


@article{communicationefficient_shi_2020,
	title = {Communication-Efficient Distributed Deep Learning with Merged Gradient Sparsification on GPUs},
	doi = {10.1109/infocom41043.2020.9155269},
	author = {Shi, Shaohuai and Wang, Qiang and Chu, Xiaowen and Li, Bo and Qin, Yang and Liu, Ruihao and Zhao, Xinxiao},
	journal = {IEEE Conference on Computer Communications},
	year = {2020},
	litmapsId = {147784147}
}


@article{grace_xu_2021,
	title = {GRACE: A Compressed Communication Framework for Distributed Machine Learning},
	doi = {10.1109/icdcs51616.2021.00060},
	author = {Xu, Hang and Ho, Chen-Yu and Abdelmoniem, Ahmed M. and Dutta, Aritra and Bergou, El Houcine and Karatsenidis, Konstantinos and Canini, Marco and Kalnis, Panos},
	journal = {IEEE International Conference on Distributed Computing Systems},
	year = {2021},
	litmapsId = {72877254}
}


@article{training_xu_2020,
	title = {Training Faster with Compressed Gradient},
	author = {Xu, An and Huo, Zhouyuan and Huang, Heng},
	journal = {arXiv: Learning},
	year = {2020},
	litmapsId = {143255273}
}


@article{bridging_zhao_2021,
	title = {Bridging the Gap Between Memory and Communication Efficiency on Distributed Deep Learning Systems},
	doi = {10.1109/access.2021.3071579},
	author = {Zhao, Shaofeng and Liu, Bo and Wang, Fang and Feng, Dan},
	journal = {IEEE Access},
	year = {2021},
	litmapsId = {70243886}
}


@article{sparse_foroutan_2020,
	title = {Sparse Communication for Training Deep Networks},
	author = {Foroutan, Negar and Jaggi, Martin},
	journal = {arXiv: Learning},
	year = {2020},
	litmapsId = {214020668}
}


@article{communicationefficient_tang_2020,
	title = {Communication-Efficient Distributed Deep Learning: A Comprehensive Survey.},
	author = {Tang, Zhenheng and Shi, Shaohuai and Chu, Xiaowen and Wang, Wei and Li, Bo},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	year = {2020},
	litmapsId = {27956446}
}


@article{communicationefficient_mcmahan_2017,
	title = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
	author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera y},
	journal = {international conference on artificial intelligence and statistics},
	year = {2017},
	litmapsId = {260883344}
}


@article{acsgd_yan_2022,
	title = {AC-SGD: Adaptively Compressed SGD for Communication-Efficient Distributed Learning},
	doi = {10.1109/jsac.2022.3192050},
	author = {Yan, Guangfeng and Li, Tan and Huang, Shao-Lun and Lan, Tian and Song, Linqi},
	journal = {IEEE Journal on Selected Areas in Communications},
	year = {2022},
	litmapsId = {240041543}
}


@article{optquant_he_2019,
	title = {OptQuant: Distributed training of neural networks with optimized quantization mechanisms},
	doi = {10.1016/j.neucom.2019.02.049},
	author = {He, Li and Zheng, Shuxin and Chen, Wei and Ma, Zhi-Ming and Liu, Tie-Yan},
	journal = {Neurocomputing},
	year = {2019},
	litmapsId = {51015780}
}


@article{quantizing_hanna_2020,
	title = {Quantizing data for distributed learning.},
	author = {Hanna, Osama A. and Ezzeldin, Yahya H. and Fragouli, Christina and Diggavi, Suhas},
	journal = {arXiv: Learning},
	year = {2020},
	litmapsId = {83739253}
}


@article{quantization_s_2021,
	title = {Quantization for Distributed Optimization.},
	author = {S, Vineeth},
	journal = {arXiv: Learning},
	year = {2021},
	litmapsId = {155031076}
}


@article{hgc_hu_2021,
	title = {HGC: Hybrid Gradient Compression in Distributed Deep Learning},
	doi = {10.1007/978-3-030-78615-1_2},
	author = {Hu, Kaifan and Wu, Chengkun and Zhu, En},
	journal = {Communications in computer and information science},
	year = {2021},
	litmapsId = {11513459}
}


@article{fast_nori_2021,
	title = {Fast Federated Learning by Balancing Communication Trade-Offs},
	doi = {10.1109/tcomm.2021.3083316},
	author = {Nori, Milad Khademi and Yun, Sangseok and Kim, Il-Min},
	journal = {IEEE Transactions on Communications},
	year = {2021},
	litmapsId = {51822793}
}


@article{masked_mohtashami_2021,
	title = {Masked Training of Neural Networks with Partial Gradients},
	author = {Mohtashami, Amirkeivan and Jaggi, Martin and Stich, Sebastian U.},
	journal = {International Conference on Artificial Intelligence and Statistics},
	year = {2021},
	litmapsId = {239839858}
}


@article{optimization_bottou_2018,
	title = {Optimization Methods for Large-Scale Machine Learning},
	doi = {10.1137/16m1080173},
	author = {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
	journal = {Siam Review},
	year = {2018},
	litmapsId = {202883596}
}


@article{rethinking_sahu_2021,
	title = {Rethinking gradient sparsification as total error minimization},
	author = {Sahu, Atal Narayan and Dutta, Aritra and Abdelmoniem, Ahmed M. and Banerjee, Trambak and Canini, Marco and Kalnis, Panos},
	journal = {Neural Information Processing Systems},
	year = {2021},
	litmapsId = {92213438}
}


@article{redsync_fang_2019,
	title = {RedSync: Reducing synchronization bandwidth for distributed deep learning training system},
	doi = {10.1016/j.jpdc.2019.05.016},
	author = {Fang, Jiarui and Fu, Haohuan and Yang, Guangwen and Hsieh, Cho-Jui},
	journal = {Journal of Parallel and Distributed Computing},
	year = {2019},
	litmapsId = {120056232}
}


@article{deep_lin_2018,
	title = {Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training},
	author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J.},
	journal = {international conference on learning representations},
	year = {2018},
	litmapsId = {261516953}
}


@article{qsgd_alistarh_2017,
	title = {QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding},
	author = {Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
	journal = {Neural Information Processing Systems},
	year = {2017},
	litmapsId = {122477394}
}


@article{sparse_aji_2017,
	title = {Sparse Communication for Distributed Gradient Descent},
	doi = {10.18653/v1/d17-1045},
	author = {Aji, Alham Fikri and Heafield, Kenneth},
	journal = {EMNLP},
	year = {2017},
	litmapsId = {82797247}
}


@article{local_stich_2019,
	title = {Local SGD Converges Fast and Communicates Little},
	author = {Stich, Sebastian U.},
	journal = {International Conference on Learning Representations},
	year = {2019},
	litmapsId = {210411970}
}


@article{accurate_goyal_2017,
	title = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
	author = {Goyal, Priya and Dollár, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
	journal = {arXiv: Computer Vision and Pattern Recognition},
	year = {2017},
	litmapsId = {260923381}
}


@article{implicit_dandi_2021,
	title = {Implicit Gradient Alignment in Distributed and Federated Learning},
	doi = {10.1609/aaai.v36i6.20597},
	author = {Dandi, Yatin and Barba, Luis and Jaggi, Martin},
	journal = {AAAI Conference on Artificial Intelligence},
	year = {2021},
	litmapsId = {61888493}
}


@article{theoretically_zhang_2023,
	title = {Theoretically Principled Federated Learning for Balancing Privacy and Utility},
	doi = {10.48550/arxiv.2305.15148},
	author = {Zhang, Xiaojin and Li, Wenjie and Chen, Kai and Xia, Shutao and Yang, Qian},
	journal = {arXiv.org},
	year = {2023},
	litmapsId = {264757668}
}


@article{largescale_he_2021,
	title = {Large-Scale Deep Learning Optimizations: A Comprehensive Survey},
	author = {He, Xiaoxin and Xue, Fuzhao and Ren, Xiaozhe and You, Yang},
	journal = {arXiv.org},
	year = {2021},
	litmapsId = {248820924}
}


@article{distributed_chen_2022,
	title = {Distributed Learning With Sparsified Gradient Differences},
	doi = {10.1109/jstsp.2022.3162989},
	author = {Chen, Yicheng and Blum, Rick S. and Takác, Martin and Sadler, B.},
	journal = {IEEE Journal on Selected Topics in Signal Processing},
	year = {2022},
	litmapsId = {84505431}
}


@article{adaptive_xu_2023,
	title = {Adaptive Control of Local Updating and Model Compression for Efficient Federated Learning},
	doi = {10.1109/tmc.2022.3186936},
	author = {Xu, Yang and Liao, Yunming and Xu, Hongli and Ma, Zhenguo and Wang, Lun and Liu, Jianchun},
	journal = {IEEE Transactions on Mobile Computing},
	year = {2023},
	litmapsId = {248512607}
}


@article{joint_lang_2023,
	title = {Joint Privacy Enhancement and Quantization in Federated Learning},
	doi = {10.1109/tsp.2023.3244092},
	author = {Lang, Natalie and Sofer, Elad and Shaked, Tomer and Shlezinger, Nir},
	journal = {IEEE Transactions on Signal Processing},
	year = {2023},
	litmapsId = {262499086}
}


@article{quicfl_basat_2022,
	title = {QUIC-FL: Quick Unbiased Compression for Federated Learning},
	doi = {10.48550/arxiv.2205.13341},
	author = {Basat, Ran Ben and Vargaftik, S. and Portnoy, Amit and Einziger, Gil and Ben-Itzhak, Y. and Mitzenmacher, M.},
	journal = {arXiv.org},
	year = {2022},
	litmapsId = {34890639}
}


@article{personalized_bergou_2022,
	title = {Personalized Federated Learning with Communication Compression},
	doi = {10.48550/arxiv.2209.05148},
	author = {Bergou, El Houcine and Burlachenko, Konstantin and Dutta, Aritra and Richt'arik, Peter},
	journal = {arXiv.org},
	year = {2022},
	litmapsId = {251833625}
}


@article{evaluation_zhang_2023,
	title = {Evaluation and Optimization of Gradient Compression for Distributed Deep Learning},
	doi = {10.1109/icdcs57875.2023.00031},
	author = {Zhang, Lin and Zhang, Longteng and Shi, S. and Chu, X. and Li, Bo},
	journal = {IEEE International Conference on Distributed Computing Systems},
	year = {2023},
	litmapsId = {262979195}
}


@article{collaborative_fan_2023,
	title = {Collaborative Learning via Prediction Consensus},
	doi = {10.48550/arxiv.2305.18497},
	author = {Fan, Dongyang and Mendler-Dunner, Celestine and Jaggi, Martin},
	journal = {arXiv.org},
	year = {2023},
	litmapsId = {262097037}
}


@article{hardwareefficient_kosson_2023,
	title = {Hardware-Efficient Transformer Training via Piecewise Affine Operations},
	doi = {10.48550/arxiv.2305.17190},
	author = {Kosson, Atli and Jaggi, Martin},
	journal = {arXiv.org},
	year = {2023},
	litmapsId = {262121136}
}


@article{deft_yoon_2023,
	title = {DEFT: Exploiting Gradient Norm Difference between Model Layers for Scalable Gradient Sparsification},
	doi = {10.1145/3605573.3605609},
	author = {Yoon, Daegun and Oh, Sangyoon},
	journal = {arXiv.org},
	year = {2023},
	litmapsId = {263365028}
}


@article{laser_makkuva_2023,
	title = {LASER: Linear Compression in Wireless Distributed Optimization},
	doi = {10.48550/arxiv.2310.13033},
	author = {Makkuva, Ashok Vardhan and Bondaschi, Marco and Vogels, Thijs and Jaggi, Martin and Kim, Hyeji and Gastpar, Michael},
	journal = {arXiv.org},
	year = {2023},
	litmapsId = {265708600}
}


@article{communicationefficient_zhou_2023,
	title = {Communication-efficient Federated Learning with Single-Step Synthetic Features Compressor for Faster Convergence},
	doi = {10.48550/arxiv.2302.13562},
	author = {Zhou, Yuhao and Shi, Mingjia and Ye, Qing and Sun, Yanan and Lv, Jiancheng},
	journal = {IEEE International Conference on Computer Vision},
	year = {2023},
	litmapsId = {254352885}
}

